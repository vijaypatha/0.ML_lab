{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'filename', 'target']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "print(dir(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LR = data.data\n",
    "y_LR = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_Test Split\n",
    "X_LR_train,X_LR_test,y_LR_train,y_LR_test = train_test_split(X_LR,y_LR,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "reg.fit(X_LR_train,y_LR_train)\n",
    "#Predict \n",
    "y_LR_pred = reg.predict(X_LR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Regression metrics\n",
    "explained_variance=metrics.explained_variance_score(y_LR_test, y_LR_pred) # The best possible score is 1.0, lower values are worse.\n",
    "mean_absolute_error=metrics.mean_absolute_error(y_LR_test, y_LR_pred) #a risk metric corresponding to the expected \n",
    "# value of the absolute error loss\n",
    "mse=metrics.mean_squared_error(y_LR_test, y_LR_pred) # a risk metric corresponding to the expected \n",
    "#value of the squared (quadratic) error or loss\n",
    "median_absolute_error=metrics.median_absolute_error(y_LR_test, y_LR_pred)\n",
    "r2=metrics.r2_score(y_LR_test, y_LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.7113\n",
      "r2:  0.7112\n",
      "MAE:  3.1627\n",
      "MSE:  21.5174\n",
      "RMSE:  4.6387\n"
     ]
    }
   ],
   "source": [
    "print('explained_variance: ', round(explained_variance,4))    \n",
    "print('r2: ', round(r2,4))\n",
    "print('MAE: ', round(mean_absolute_error,4))\n",
    "print('MSE: ', round(mse,4))\n",
    "print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y\n",
    "X_RR = data.data\n",
    "y_RR = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test\n",
    "X_RR_train, X_RR_test,y_RR_train,y_RR_test = train_test_split(X_RR, y_RR,test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate\n",
    "param_grid={'alpha': [0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
    "       0.65, 0.7 , 0.75]}\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit \n",
    "ridge_cv.fit(X_RR_train,y_RR_train)\n",
    "\n",
    "#predict\n",
    "y_RR_pred = ridge_cv.predict(X_RR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7130103046471367\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(ridge_cv.best_score_)\n",
    "print(ridge_cv.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "from sklearn import metrics\n",
    "# Regression metrics\n",
    "explained_variance=metrics.explained_variance_score(y_RR_test, y_RR_pred) # The best possible score is 1.0, lower values are worse.\n",
    "mean_absolute_error=metrics.mean_absolute_error(y_RR_test, y_RR_pred) #a risk metric corresponding to the expected \n",
    "# value of the absolute error loss\n",
    "mse=metrics.mean_squared_error(y_RR_test, y_RR_pred) # a risk metric corresponding to the expected \n",
    "#value of the squared (quadratic) error or loss\n",
    "median_absolute_error=metrics.median_absolute_error(y_RR_test, y_RR_pred)\n",
    "r2=metrics.r2_score(y_RR_test, y_RR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.7104\n",
      "r2:  0.7103\n",
      "MAE:  3.1624\n",
      "MSE:  21.5851\n",
      "RMSE:  4.646\n"
     ]
    }
   ],
   "source": [
    "print('explained_variance: ', round(explained_variance,4))    \n",
    "print('r2: ', round(r2,4))\n",
    "print('MAE: ', round(mean_absolute_error,4))\n",
    "print('MSE: ', round(mse,4))\n",
    "print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LASSO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
